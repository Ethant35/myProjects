{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Code example\n",
        "\n",
        "The following is an example of how to generate code from a trained keras model.\n",
        "\n",
        "This is just an example, but if you want to run it, you can download `prideandprejudice.txt` and `exampmodel.zip` from Canvas, upload it here, and run.\n",
        "\n",
        "## Load packages"
      ],
      "metadata": {
        "id": "yL6tZu_z2pmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as kb\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import string\n",
        "from random import randint\n",
        "from pickle import load\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import Model"
      ],
      "metadata": {
        "id": "luZPccZi78-U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load File and Generate Sequences"
      ],
      "metadata": {
        "id": "IXHiHrux24Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        " # open the file as read only\n",
        " file = open(filename, 'r', encoding='utf-8')\n",
        " # read all text\n",
        " text = file.read()\n",
        " # close the file\n",
        " file.close()\n",
        " return text\n",
        "\n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        " # replace '--' with a space ' '\n",
        " doc = doc.replace('--', ' ')\n",
        " # split into tokens by white space\n",
        " tokens = doc.split()\n",
        " # remove punctuation from each token\n",
        " table = str.maketrans('', '', string.punctuation)\n",
        " tokens = [w.translate(table) for w in tokens]\n",
        " # remove remaining tokens that are not alphabetic\n",
        " tokens = [word for word in tokens if word.isalpha()]\n",
        " # make lower case\n",
        " tokens = [word.lower() for word in tokens]\n",
        " return tokens\n",
        "\n",
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        " data = '\\n'.join(lines)\n",
        " file = open(filename, 'w')\n",
        " file.write(data)\n",
        " file.close()\n",
        "\n",
        "# load document\n",
        "in_filename = 'Shake.txt'\n",
        "doc = load_doc(in_filename)\n",
        "print(doc[:200])\n",
        "\n",
        "# clean document\n",
        "tokens = clean_doc(doc)\n",
        "print(tokens[:200])\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "print('Unique Tokens: %d' % len(set(tokens)))\n",
        "\n",
        "# organize into sequences of tokens\n",
        "length = 20 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens)):\n",
        " # select sequence of tokens\n",
        " seq = tokens[i-length:i]\n",
        " # convert into a line\n",
        " line = ' '.join(seq)\n",
        " # store\n",
        " sequences.append(line)\n",
        "print('Total Sequences: %d' % len(sequences))\n",
        "\n",
        "# save sequences to file\n",
        "out_filename = 'Shake_sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih_e_uRa1EOS",
        "outputId": "6039b256-ca95-417b-adfb-e6a85bf9d51c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title: Romeo and Juliet\n",
            "\n",
            "Author: William Shakespeare\n",
            "\n",
            "Release date: November 1, 1998 [eBook #1513]\n",
            "                Most recently updated: June 27, 2023\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: the PG Shakespeare\n",
            "['title', 'romeo', 'and', 'juliet', 'author', 'william', 'shakespeare', 'release', 'date', 'november', 'ebook', 'most', 'recently', 'updated', 'june', 'language', 'english', 'credits', 'the', 'pg', 'shakespeare', 'team', 'a', 'team', 'of', 'about', 'twenty', 'project', 'gutenberg', 'volunteers', 'start', 'of', 'the', 'project', 'gutenberg', 'ebook', 'romeo', 'and', 'juliet', 'the', 'tragedy', 'of', 'romeo', 'and', 'juliet', 'by', 'william', 'shakespeare', 'contents', 'the', 'prologue', 'act', 'i', 'scene', 'i', 'a', 'public', 'place', 'scene', 'ii', 'a', 'street', 'scene', 'iii', 'room', 'in', 'house', 'scene', 'iv', 'a', 'street', 'scene', 'v', 'a', 'hall', 'in', 'house', 'act', 'ii', 'chorus', 'scene', 'i', 'an', 'open', 'place', 'adjoining', 'garden', 'scene', 'ii', 'garden', 'scene', 'iii', 'friar', 'cell', 'scene', 'iv', 'a', 'street', 'scene', 'v', 'garden', 'scene', 'vi', 'friar', 'cell', 'act', 'iii', 'scene', 'i', 'a', 'public', 'place', 'scene', 'ii', 'a', 'room', 'in', 'house', 'scene', 'iii', 'friar', 'cell', 'scene', 'iv', 'a', 'room', 'in', 'house', 'scene', 'v', 'an', 'open', 'gallery', 'to', 'chamber', 'overlooking', 'the', 'garden', 'act', 'iv', 'scene', 'i', 'friar', 'cell', 'scene', 'ii', 'hall', 'in', 'house', 'scene', 'iii', 'chamber', 'scene', 'iv', 'hall', 'in', 'house', 'scene', 'v', 'chamber', 'juliet', 'on', 'the', 'bed', 'act', 'v', 'scene', 'i', 'mantua', 'a', 'street', 'scene', 'ii', 'friar', 'cell', 'scene', 'iii', 'a', 'churchyard', 'in', 'it', 'a', 'monument', 'belonging', 'to', 'the', 'capulets', 'dramatis', 'person√¶', 'escalus', 'prince', 'of', 'verona', 'mercutio', 'kinsman', 'to', 'the', 'prince', 'and', 'friend']\n",
            "Total Tokens: 25056\n",
            "Unique Tokens: 3385\n",
            "Total Sequences: 25035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load\n",
        "in_filename = 'Shake_sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')"
      ],
      "metadata": {
        "id": "bM4aoW1p1WVb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "metadata": {
        "id": "vDAJkrpT1aFb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create sequences\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = kb.utils.to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "metadata": {
        "id": "-5okv1kg1czQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# My initial LSTM model\n",
        "inputs = Input(shape=(X.shape[1], 1))\n",
        "x = LSTM(256)(inputs)\n",
        "x = Dropout(0.2)(x)\n",
        "output = Dense(vocab_size, activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics='accuracy')"
      ],
      "metadata": {
        "id": "AGIOVRyWNoY-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=40, batch_size=128,verbose=0)"
      ],
      "metadata": {
        "id": "jN3Ek1XcN2XP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6abb9a17-dba5-4567-8a30-e8b090824dcb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a25439cafb0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, evaluate the model on the same dataset to get the loss and metrics\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "\n",
        "# Print the loss and accuracy\n",
        "print(f'Final loss: {loss}')\n",
        "print(f'Final accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "XS-hdnaePDOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6508082d-83dc-4ef4-f609-03d0daf66723"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 2.6925363540649414\n",
            "Final accuracy: 0.45420411229133606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Text\n",
        "\n",
        "This loops through to generate long strings of text using the seed text + any generated tokens to predict the next token."
      ],
      "metadata": {
        "id": "ilQetMSZ3Ks-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MaXXbiQSy2J6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b68ed38-b927-4e5a-9cec-76b58aa34a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed text:  send to romeo but when i came some minute ere the time of her awaking here untimely lay the noble paris\n",
            "GENDERATED TEXT: come i prince servant romeo romeo romeo madam that thou death not that the montague the may so nurse groan\n",
            "\n",
            "\n",
            "Seed text:  and his brother valentine mine uncle capulet his wife and daughters my fair niece rosaline and livia signior valentio and his\n",
            "GENDERATED TEXT: cousin and daughters of his moved and the lively helena of the unseen button of the watery flask of duellist\n",
            "\n",
            "\n",
            "Seed text:  of substance as the air and more inconstant than the wind who woos even now the frozen bosom of the north\n",
            "GENDERATED TEXT: of the capulets of the capulets sampson the the capulets place and immortal passado of the capulets came the immortal\n",
            "\n",
            "\n",
            "Seed text:  her silver why why with her silver what say you simon catling first musician marry sir because silver hath a sweet\n",
            "GENDERATED TEXT: sound the then the me that both one that a comfort i tell i will for civil within to heads\n",
            "\n",
            "\n",
            "Seed text:  rode i think he told me paris should have married juliet said he not so or did i dream it so\n",
            "GENDERATED TEXT: i am fool of my dear juliet nurse is is house so young bachelor and tell r and tell r\n",
            "\n",
            "\n",
            "Seed text:  pity you at odds so long but now my lord what say you to my suit capulet but saying what i\n",
            "GENDERATED TEXT: have said you thee i am so you wilt so of bid my great romeo i must wed to you\n",
            "\n",
            "\n",
            "Seed text:  thy hand late farewell good night romeo but that a joy past joy calls out on me it were a grief\n",
            "GENDERATED TEXT: some that sadness and would i world my dreams and know and friend it is it pardon you not not\n",
            "\n",
            "\n",
            "Seed text:  here in this city visiting the sick and finding him the searchers of the town suspecting that we both were in\n",
            "GENDERATED TEXT: a house i montague the montague be trust ah the montague i make to die nobleman to have to fortunes\n",
            "\n",
            "\n",
            "Seed text:  them above a common bound romeo i am too sore enpierced with his shaft to soar with his light feathers and\n",
            "GENDERATED TEXT: be bound i be moody and as soon moody and his soon moody and his stirs of utruvio of his\n",
            "\n",
            "\n",
            "Seed text:  a surgeon exit page romeo courage man the hurt cannot be much mercutio no not so deep as a well nor\n",
            "GENDERATED TEXT: a plague my my course nurse lawrence aside to slave to broad to cannot it a it and some the\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "    result = list()\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        # Encode the text as integers\n",
        "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        # Pad sequences to a fixed length\n",
        "        encoded = kb.preprocessing.sequence.pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "        # Predict probabilities for each word\n",
        "        yhat = model.predict(encoded, verbose=0)\n",
        "        # Get the highest probability word index\n",
        "        yhat = np.argmax(yhat, axis=-1)\n",
        "        # Map predicted word index to word\n",
        "        out_word = tokenizer.index_word.get(yhat[0], '')  # Use .get to avoid KeyErrors and provide a default\n",
        "        # If no word is found, break the loop\n",
        "        if out_word == '':\n",
        "            print('Unable to find a word for the index predicted.')\n",
        "            break\n",
        "        # Append to the result\n",
        "        result.append(out_word)\n",
        "        # Update the seed text with the new word\n",
        "        in_text += ' ' + out_word\n",
        "        # Use only the last 'seq_length' words to generate the next word\n",
        "        in_text = ' '.join(in_text.split()[-seq_length:])\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Generate new text 10x\n",
        "for i in range(10):\n",
        "  seed_text = lines[randint(0, len(lines))]\n",
        "  print(\"Seed text: \", seed_text)\n",
        "  generated = generate_seq(model, tokenizer, seq_length, seed_text, 20)\n",
        "  print(\"GENDERATED TEXT:\", generated + '\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New model architecture with the mulitple recurrent layers\n",
        "newmodel = Sequential()\n",
        "#Three recurrent layers\n",
        "newmodel.add(LSTM(128, return_sequences=True))\n",
        "newmodel.add(LSTM(64, return_sequences=True))\n",
        "newmodel.add(LSTM(32,return_sequences=True))\n",
        "\n",
        "newmodel.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "newmodel = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "newmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "newmodel.fit(X, y, epochs=40, batch_size=128, verbose=0)"
      ],
      "metadata": {
        "id": "FHkpBovoS_2r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619631f0-9505-48ab-bd07-e5985b5cd176"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a25b2c57280>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, evaluate the model on the same dataset to get the loss and metrics\n",
        "loss, accuracy = newmodel.evaluate(X, y, verbose=0)\n",
        "\n",
        "# Print the loss and accuracy\n",
        "print(f'Final loss: {loss}')\n",
        "print(f'Final accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "XjC0Vu4dQoKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ba9404-6234-49cf-f771-94b43efbdf5f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: 1.3925262689590454\n",
            "Final accuracy: 0.7179948091506958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new text 10x\n",
        "for i in range(10):\n",
        "  seed_text = lines[randint(0, len(lines))]\n",
        "  print(\"Seed text: \", seed_text)\n",
        "  generated = generate_seq(newmodel, tokenizer, seq_length, seed_text, 20)\n",
        "  print(\"GENDERATED TEXT:\", generated + '\\n\\n')"
      ],
      "metadata": {
        "id": "C2PldTEhUE2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48e890f-d323-45d5-cb90-b9104435f9dd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed text:  lawrence now must i to the monument alone within this three hours will fair juliet wake she will beshrew me much\n",
            "GENDERATED TEXT: the romeo my night o was be of a be that a grief that a which love as what is\n",
            "\n",
            "\n",
            "Seed text:  men either withdraw unto some private place and reason coldly of your grievances or else depart here all eyes gaze on\n",
            "GENDERATED TEXT: us and to peace and balthasar of death thou in can word of young me tell be tell be tell\n",
            "\n",
            "\n",
            "Seed text:  doth give nor aught so good but from that fair use revolts from true birth stumbling on abuse virtue itself turns\n",
            "GENDERATED TEXT: vice vice vice the vice of the beast of the house and bakes of the watery beams of the watery\n",
            "\n",
            "\n",
            "Seed text:  it to my face paris thy face is mine and thou hast it juliet it may be so for it is\n",
            "GENDERATED TEXT: not mine own you life you that my lady o thou her thou my her love your that man price\n",
            "\n",
            "\n",
            "Seed text:  is paris have i thought long to see this face and doth it give me such a sight as this lady\n",
            "GENDERATED TEXT: capulet unhappy wretched hateful day most miserable in many in the must for a his now and will be all\n",
            "\n",
            "\n",
            "Seed text:  you think fit to furnish me tomorrow lady capulet no not till thursday there is time enough capulet go nurse go\n",
            "GENDERATED TEXT: with her to church tomorrow the think o what the am i the cease of her i her my dear\n",
            "\n",
            "\n",
            "Seed text:  apt to quarrel as thou art any man should buy the fee simple of my life for an hour and a\n",
            "GENDERATED TEXT: quarter mercutio him what be nurse and what juliet still to tender that his my soul my his wisdom him\n",
            "\n",
            "\n",
            "Seed text:  patience your looks are pale and wild and do import some misadventure romeo tush thou art leave me and do the\n",
            "GENDERATED TEXT: thing i bid with for thou world to thou let me do my love with more she and tell thee\n",
            "\n",
            "\n",
            "Seed text:  not what to say peter o i cry you mercy you are the singer i will say for you it is\n",
            "GENDERATED TEXT: is her a some your she you is thus that life that a grave juliet i will i love so\n",
            "\n",
            "\n",
            "Seed text:  of love this unbound lover to beautify him only lacks a cover the fish lives in the sea and much pride\n",
            "GENDERATED TEXT: of the project web of the watery beams of the watery beams to what is is it and goose i\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}